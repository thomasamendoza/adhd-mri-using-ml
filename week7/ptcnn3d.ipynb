{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "if torch.backends.mps.is_available():\n",
    "    mps_device = torch.device(\"mps\")\n",
    "    x = torch.ones(1, device=mps_device)\n",
    "    print (x)\n",
    "else:\n",
    "    print (\"MPS device not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMCLASSES = 5\n",
    "TRAINPATH = 'UCF101Dataset/train'\n",
    "TESTPATH = 'UCF101Dataset/test'\n",
    "TRAINLABELSPATH = 'UCF101Dataset/train.csv'\n",
    "TESTLABELSPATH = 'UCF101Dataset/test.csv'\n",
    "train_df = pd.read_csv(TRAINLABELSPATH)\n",
    "test_df = pd.read_csv(TESTLABELSPATH)\n",
    "\n",
    "\"\"\"\n",
    "    Loads and frames from the provided file path\n",
    "    \n",
    "    returns: numpy array of generated frames\n",
    "\"\"\"\n",
    "\n",
    "def load_frames(path, numFrames=16): \n",
    "\n",
    "    cap = cv2.VideoCapture(path) # opening video\n",
    "    frames = []\n",
    "\n",
    "    totalFrames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    frameInterval = max(totalFrames // numFrames, 1)\n",
    "    for i in range(numFrames):\n",
    "        cap.set(cv2.CAP_PROP_POS_FRAMES, i*frameInterval) # set frame position\n",
    "        ret, frame = cap.read() # read frame at position\n",
    "\n",
    "        if not ret: # exit loop if at end of video\n",
    "            break\n",
    "\n",
    "        frame = cv2.resize(frame, (112,112))\n",
    "        frames.append(frame)\n",
    "\n",
    "    while len(frames) < numFrames:\n",
    "        frames.append(np.zeros((112,112,3), np.uint8)) # fill in blank frames with zeroes \n",
    "\n",
    "    return np.array(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoDataset(Dataset):\n",
    "    def __init__(self, paths,labels):\n",
    "        self.paths = paths\n",
    "        self.labels = labels\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self,x):\n",
    "        path = self.paths[x]\n",
    "        label = self.labels[x]\n",
    "        \n",
    "        frames = torch.tensor(load_frames(path))\n",
    "        frames = frames.float()\n",
    "\n",
    "        return frames, label\n",
    "    \n",
    "class VideoClassifier(nn.Module):\n",
    "    def __init__(self,numClasses):\n",
    "        super(VideoClassifier, self).__init__()\n",
    "        self.conv3D1 = nn.Conv3d(3,64, kernel_size=(3,3,3), padding=(1,1,1))\n",
    "        self.conv3D2 = nn.Conv3d(64,128, kernel_size=(3,3,3), padding=(1,1,1))\n",
    "        self.conv3D3 = nn.Conv3d(128,256, kernel_size=(3,3,3), padding=(1,1,1))\n",
    "\n",
    "        self.FC1 = nn.Linear(256*4*4*4, 128)\n",
    "        self.FC2 = nn.Linear(128, numClasses)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool3d(self.conv3D1(x), kernel_size=(2,2,2)))\n",
    "        x = F.relu(F.max_pool3d(self.conv3D2(x), kernel_size=(2,2,2)))\n",
    "        x = F.relu(F.max_pool3d(self.conv3D3(x), kernel_size=(2,2,2)))\n",
    "        \n",
    "        x = x.reshape(-1, 256*4*4*4)\n",
    "\n",
    "        x = F.relu(self.FC1(x))\n",
    "        x = self.FC2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'iterrows'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Load and preprocess the training and testing data\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m X_train, y_train \u001b[38;5;241m=\u001b[39m \u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_video_paths\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mNUMCLASSES\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m X_test, y_test \u001b[38;5;241m=\u001b[39m load_data(test_labels, test_video_paths, NUMCLASSES)\n",
      "Cell \u001b[0;32mIn[17], line 23\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(labels, video_dir, num_classes, num_frames)\u001b[0m\n\u001b[1;32m     20\u001b[0m y \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Iterate through each row in the labels DataFrame\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, row \u001b[38;5;129;01min\u001b[39;00m \u001b[43mlabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterrows\u001b[49m():\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;66;03m# Construct the path to the video file\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     video_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(video_dir, row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvideo_name\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Extract frames from the video\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'iterrows'"
     ]
    }
   ],
   "source": [
    "train_video_paths = 'week7/UCF101Dataset/train/' + train_df['video_name'].values\n",
    "train_labels = train_df['tag'].values\n",
    "\n",
    "test_video_paths = 'week7/UCF101Dataset/test/' + test_df['video_name'].values\n",
    "test_labels = test_df['tag'].values\n",
    "\n",
    "traindataset = VideoDataset(train_video_paths, train_labels)\n",
    "traindataloader = DataLoader(traindataset, batch_size=32, shuffle=True)\n",
    "\n",
    "testdataset = VideoDataset(test_video_paths, test_labels)\n",
    "testdataloader = DataLoader(testdataset, batch_size=32, shuffle=False)\n",
    "\n",
    "model = VideoClassifier(NUMCLASSES)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "lossFunction = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "def load_data(labels, video_dir, num_classes, num_frames=16):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # Iterate through each row in the labels DataFrame\n",
    "    for idx, row in labels.iterrows():\n",
    "        # Construct the path to the video file\n",
    "        video_path = os.path.join(video_dir, row['video_name'])\n",
    "        \n",
    "        # Extract frames from the video\n",
    "        frames = load_frames(video_path, num_frames)\n",
    "        \n",
    "        # Check if the correct number of frames were extracted\n",
    "        if len(frames) == num_frames:\n",
    "            X.append(frames)\n",
    "            y.append(row['tag'])\n",
    "    \n",
    "    # Convert the lists to NumPy arrays\n",
    "    X = np.array(X)\n",
    "    \n",
    "    # Convert the labels to one-hot encoded format\n",
    "    y = np.eye(num_classes, dtype='uint8')[y]\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "# Load and preprocess the training and testing data\n",
    "X_train, y_train = load_data(train_labels, train_video_paths, NUMCLASSES)\n",
    "X_test, y_test = load_data(test_labels, test_video_paths, NUMCLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL TRAINING\n",
    "for epoch in range(10):\n",
    "    for batch in traindataloader:\n",
    "        frames, labels = batch\n",
    "        inputs = frames.permute(0,4,1,2,3) # convert dimensions\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        print(f'Inputs shape: {inputs.shape}')\n",
    "        print(f'Outputs shape: {outputs.shape}')\n",
    "        print(f'Labels shape: {labels}')\n",
    "        \n",
    "        loss = lossFunction(outputs, torch.tensor(labels))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f'Epoch {epoch+1}, Loss: {loss.item()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable int object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# MODEL TESTING\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m----> 3\u001b[0m testLoss,correct \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m testdataloader:\n",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable int object"
     ]
    }
   ],
   "source": [
    "# MODEL TESTING\n",
    "model.eval()\n",
    "testLoss,correct = 0\n",
    "with torch.no_grad():\n",
    "    for batch in testdataloader:\n",
    "        frames, labels = batch\n",
    "        inputs = frames.permute(0,4,1,2,3)\n",
    "        outputs = model(inputs)\n",
    "        loss = lossFunction(outputs, labels)\n",
    "        testLoss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        correct += (predicted == labels).sum().item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = correct / len(testdataset)\n",
    "print(f'Test Loss: {testLoss/len(testdataloader)}')\n",
    "print(f'Accuracy: {accuracy:.2f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3DCNN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
