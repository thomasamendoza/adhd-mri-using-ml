{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:23:49.531694Z",
     "start_time": "2024-10-16T18:23:49.528009Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 00:12:41.279380: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-11-20 00:12:41.286233: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1732083161.294279   18518 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1732083161.296699   18518 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-11-20 00:12:41.305152: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Import Necessary Libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import nibabel as nib\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import center_of_mass\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['TF_GPU_ALLOCATOR']='cuda_malloc_async'\n",
    "\n",
    "keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:23:49.544127Z",
     "start_time": "2024-10-16T18:23:49.541268Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using only GPU: PhysicalDevice(name='/physical_device:GPU:1', device_type='GPU')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1732083162.460361   18518 gpu_process_state.cc:201] Using CUDA malloc Async allocator for GPU: 1\n",
      "I0000 00:00:1732083162.468515   18518 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 18438 MB memory:  -> device: 1, name: NVIDIA RTX 4000 Ada Generation, pci bus id: 0000:02:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "# Set up environment for GPU allocation\n",
    "#os.environ['TF_GPU_ALLOCATOR'] = 'cuda_malloc_async'\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        tf.config.set_visible_devices(gpus[1], 'GPU')\n",
    "        print(f\"Using only GPU: {gpus[1]}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print(\"No GPUs found.\")\n",
    "\n",
    "strategy = tf.distribute.OneDeviceStrategy(device=\"/gpu:1\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO: have the subject_ids be read dynamically from the tsv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:23:49.565592Z",
     "start_time": "2024-10-16T18:23:49.560332Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 2: Define Paths and Subject IDs\n",
    "\n",
    "data_dir = '/home/zaz22/research-data-store/fmri/fmri_beijing'\n",
    "mapping_file = '/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz'\n",
    "phenotypic_file = '/home/zaz22/repos/adhd-mri-using-ml/adhd200_preprocessed_phenotypics.tsv'\n",
    "\n",
    "subject_ids = ['9640133', '9783279', '9887336', '9890726', '4095748', '4136226', '4221029',\n",
    "    '4225073', '4241194', '4256491', '4265987', '4334113', '4383707', '4475709',\n",
    "    '4921428', '5150328', '5193577', '5575344', '5600820', '5669389', '5993008',\n",
    "    '6187322', '6383713', '6477085', '6500128', '7011503', '7093319', '7135128',\n",
    "    '7253183', '7390867', '7407032', '7689953', '7994085', '8191384', '8278680',]\n",
    "\n",
    "# subject_ids = [\n",
    "#     '9640133', '9783279', '9887336', '9890726', '4095748', '4136226', '4221029',\n",
    "#     '4225073', '4241194', '4256491', '4265987', '4334113', '4383707', '4475709',\n",
    "#     '4921428', '5150328', '5193577', '5575344', '5600820', '5669389', '5993008',\n",
    "#     '6187322', '6383713', '6477085', '6500128', '7011503', '7093319', '7135128',\n",
    "#     '7253183', '7390867', '7407032', '7689953', '7994085', '8191384', '8278680',\n",
    "#     '8328877', '8838009', '9002207', '9093997', '9210521', '9221927', '9578631',\n",
    "#     '3494778', '3554582', '3561920', '3562883', '3587000', '3593327', '3610134',\n",
    "#     '3624598', '3655623', '3672300', '3672854', '3691107', '3707771', '3712305',\n",
    "#     '3732101', '3739175', '3803759', '3809753', '3827352', '3856956', '3870624',\n",
    "#     '3889095', '3910672', '3930512', '3967265', '3976121', '3983607', '3993793',\n",
    "#     '3994098', '4006710', '4028266', '4048810', '4053388', '4053836', '4055710',\n",
    "#     '4073815', '4075719', '4091983', '2538839', '2559537', '2601519', '2659769',\n",
    "#     '2697768', '2703336', '2714224', '2737106', '2780647', '2833684', '2884672',\n",
    "#     '2897046', '2907951', '2910270', '2919220', '2940712', '2950754', '2984158',\n",
    "#     '3004580', '3086074', '3157406', '3194757', '3205761', '3212536', '3224401',\n",
    "#     '3233028', '3239413', '3248920', '3262042', '3269608', '3277313', '3291029',\n",
    "#     '3306863', '3308331', '3385520', '3390312', '3446674', '3473830', '1809715',\n",
    "#     '1843546', '1860323', '1875013', '1875711', '1879542', '1912810', '1916266',\n",
    "#     '1947991', '2031422', '2033178', '2081754', '2106109', '2107404', '2123983',\n",
    "#     '2140063', '2141250', '2174595', '2196753', '2207418', '2208591', '2228148',\n",
    "#     '2240562', '2249443', '2266806', '2268253', '2276801', '2296326', '2310449',\n",
    "#     '2367157', '2377207', '2408774', '2427408', '2493190', '2498847', '2524687',\n",
    "#     '2529026', '2535087', '1050345', '1050975', '1056121', '1068505', '1093743',\n",
    "#     '1094669', '1113498', '1117299', '1132854', '1133221', '1139030', '1159908',\n",
    "#     '1177160', '1186237', '1240299', '1258069', '1282248', '1302449', '1341865',\n",
    "#     '1356553', '1391181', '1399863', '1404738', '1408093', '1411536', '1469171',\n",
    "#     '1494102', '1561488', '1562298', '1628610', '1643780', '1662160', '1686092',\n",
    "#     '1689948', '1771270', '1791543', '1794770', '1805037'\n",
    "# ]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:29:21.496568Z",
     "start_time": "2024-10-16T18:23:49.571584Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of ROIs: 2843\n",
      "Loading functional image for 9640133 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_9640133_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "Resampling labels\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_9640133_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 9640133 with shape (236, 2843)\n",
      "Loading functional image for 9783279 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_9783279_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_9783279_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 9783279 with shape (236, 2843)\n",
      "Loading functional image for 9887336 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_9887336_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_9887336_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 9887336 with shape (236, 2843)\n",
      "Loading functional image for 9890726 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_9890726_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_9890726_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 9890726 with shape (236, 2843)\n",
      "Loading functional image for 4095748 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_4095748_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_4095748_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 4095748 with shape (236, 2843)\n",
      "Loading functional image for 4136226 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_4136226_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_4136226_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 4136226 with shape (236, 2843)\n",
      "Loading functional image for 4221029 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_4221029_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_4221029_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 4221029 with shape (236, 2843)\n",
      "Loading functional image for 4225073 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_4225073_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_4225073_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 4225073 with shape (236, 2843)\n",
      "Loading functional image for 4241194 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_4241194_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_4241194_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 4241194 with shape (236, 2843)\n",
      "Loading functional image for 4256491 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_4256491_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_4256491_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 4256491 with shape (236, 2843)\n",
      "Loading functional image for 4265987 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_4265987_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_4265987_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 4265987 with shape (236, 2843)\n",
      "Loading functional image for 4334113 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_4334113_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_4334113_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 4334113 with shape (236, 2843)\n",
      "Loading functional image for 4383707 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_4383707_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_4383707_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 4383707 with shape (236, 2843)\n",
      "Loading functional image for 4475709 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_4475709_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_4475709_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 4475709 with shape (236, 2843)\n",
      "Loading functional image for 4921428 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_4921428_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_4921428_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 4921428 with shape (236, 2843)\n",
      "Loading functional image for 5150328 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_5150328_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_5150328_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 5150328 with shape (236, 2843)\n",
      "Loading functional image for 5193577 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_5193577_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_5193577_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 5193577 with shape (236, 2843)\n",
      "Loading functional image for 5575344 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_5575344_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_5575344_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 5575344 with shape (236, 2843)\n",
      "Loading functional image for 5600820 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_5600820_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_5600820_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 5600820 with shape (236, 2843)\n",
      "Loading functional image for 5669389 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_5669389_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_5669389_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 5669389 with shape (236, 2843)\n",
      "Loading functional image for 5993008 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_5993008_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_5993008_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 5993008 with shape (236, 2843)\n",
      "Loading functional image for 6187322 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_6187322_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_6187322_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 6187322 with shape (236, 2843)\n",
      "Loading functional image for 6383713 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_6383713_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_6383713_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 6383713 with shape (236, 2843)\n",
      "Loading functional image for 6477085 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_6477085_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_6477085_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 6477085 with shape (236, 2843)\n",
      "Loading functional image for 6500128 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_6500128_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_6500128_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 6500128 with shape (236, 2843)\n",
      "Loading functional image for 7011503 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_7011503_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_7011503_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 7011503 with shape (236, 2843)\n",
      "Loading functional image for 7093319 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_7093319_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_7093319_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 7093319 with shape (236, 2843)\n",
      "Loading functional image for 7135128 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_7135128_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_7135128_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 7135128 with shape (236, 2843)\n",
      "Loading functional image for 7253183 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_7253183_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_7253183_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 7253183 with shape (236, 2843)\n",
      "Loading functional image for 7390867 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_7390867_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_7390867_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 7390867 with shape (236, 2843)\n",
      "Loading functional image for 7407032 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_7407032_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_7407032_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 7407032 with shape (236, 2843)\n",
      "Loading functional image for 7689953 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_7689953_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_7689953_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 7689953 with shape (236, 2843)\n",
      "Loading functional image for 7994085 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_7994085_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_7994085_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 7994085 with shape (236, 2843)\n",
      "Loading functional image for 8191384 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_8191384_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_8191384_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 8191384 with shape (236, 2843)\n",
      "Loading functional image for 8278680 from /home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_8278680_session_1_run1.nii.gz\n",
      "[NiftiLabelsMasker.wrapped] loading data from Minc1Image('/home/zaz22/research-data-store/rois/rois_3000_beijing/rois/brain_atoms.mnc.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Loading data from Nifti1Image('/home/zaz22/research-data-store/fmri/fmri_beijing/fmri_X_8278680_session_1_run1.nii.gz')\n",
      "[NiftiLabelsMasker.transform_single_imgs] Extracting region signals\n",
      "[NiftiLabelsMasker.transform_single_imgs] Cleaning extracted signals\n",
      "Extracted time series for 8278680 with shape (236, 2843)\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Load Functional Images and Extract Time Series for All Subjects\n",
    "\n",
    "# Load the ROI mapping image (we'll use this to extract time series)\n",
    "mapping_img = nib.load(mapping_file)\n",
    "mapping_data = mapping_img.get_fdata()\n",
    "affine = mapping_img.affine\n",
    "\n",
    "# Get the unique labels (excluding 0)\n",
    "roi_labels = np.unique(mapping_data)\n",
    "roi_labels = roi_labels[roi_labels != 0]\n",
    "n_rois = len(roi_labels)\n",
    "\n",
    "print(f'Number of ROIs: {n_rois}')\n",
    "\n",
    "# Create a masker for extracting time series from ROIs\n",
    "from nilearn.maskers import NiftiLabelsMasker\n",
    "\n",
    "labels_masker = NiftiLabelsMasker(\n",
    "    labels_img=mapping_img,\n",
    "    standardize=True,\n",
    "    detrend=True,\n",
    "    t_r=2.0,  # Replace with your TR (repetition time)\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Initialize a list to store time series for all subjects\n",
    "all_tseries = []\n",
    "\n",
    "for sub_id in subject_ids:\n",
    "    # data/fmri/beijing/fmri_X_1050345_session_1_run1.nii.gz\n",
    "    func_file = os.path.join(data_dir, f'fmri_X_{sub_id}_session_1_run1.nii.gz')\n",
    "    print(f'Loading functional image for {sub_id} from {func_file}')\n",
    "    \n",
    "    # Load the functional image\n",
    "    func_img = nib.load(func_file)\n",
    "    \n",
    "    # Extract time series using the labels masker\n",
    "    tseries = labels_masker.fit_transform(func_img)\n",
    "    \n",
    "    all_tseries.append(tseries)\n",
    "    \n",
    "    print(f'Extracted time series for {sub_id} with shape {tseries.shape}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:29:22.659090Z",
     "start_time": "2024-10-16T18:29:21.510096Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 4: Extract ROI Coordinates (Same as Before)\n",
    "\n",
    "# Extract ROI coordinates (center of mass)\n",
    "roi_coords = []\n",
    "\n",
    "for label in roi_labels:\n",
    "    # Create a binary mask for the current ROI\n",
    "    roi_mask = mapping_data == label\n",
    "\n",
    "    # Calculate the center of mass in voxel space\n",
    "    com_voxel = center_of_mass(roi_mask)\n",
    "\n",
    "    # Convert voxel coordinates to world coordinates using the affine matrix\n",
    "    com_world = nib.affines.apply_affine(affine, com_voxel)\n",
    "\n",
    "    roi_coords.append(com_world)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:29:22.670932Z",
     "start_time": "2024-10-16T18:29:22.667971Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects: 35\n",
      "Number of ROIs in time series data: 2843\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Verify Alignment Between Time Series and ROI Labels\n",
    "\n",
    "n_subjects = len(all_tseries)\n",
    "\n",
    "# Check that all time series have the same number of ROIs\n",
    "for idx, tseries in enumerate(all_tseries):\n",
    "    assert tseries.shape[1] == n_rois, f\"Mismatch in number of ROIs for subject {subject_ids[idx]}\"\n",
    "\n",
    "print(f'Number of subjects: {n_subjects}')\n",
    "print(f'Number of ROIs in time series data: {n_rois}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:30:30.057084Z",
     "start_time": "2024-10-16T18:29:22.680116Z"
    }
   },
   "outputs": [],
   "source": [
    "# Step 6: Compute Functional Connectivity Matrices for All Subjects\n",
    "# import seaborn as sns\n",
    "\n",
    "# Initialize the connectivity measure (using Pearson correlation)\n",
    "correlation_measure = ConnectivityMeasure(kind='correlation')\n",
    "\n",
    "# Compute correlation matrices\n",
    "all_correlation_matrices = correlation_measure.fit_transform(all_tseries)\n",
    "\n",
    "# for x in range(len(all_correlation_matrices)):\n",
    "#     correlation_matrix = all_correlation_matrices[x]\n",
    "\n",
    "#     # Create a figure and axis\n",
    "#     plt.figure(figsize=(5,4))\n",
    "\n",
    "#     # Plot the heatmap using seaborn\n",
    "#     sns.heatmap(correlation_matrix, vmin=-1, vmax=1, cmap='coolwarm', square=True, cbar=True)\n",
    "\n",
    "#     # Add title and labels\n",
    "#     plt.title(f'Subject {x+1} Functional Connectivity Matrix')\n",
    "#     plt.xlabel('ROIs')\n",
    "#     plt.ylabel('ROIs')\n",
    "\n",
    "#     # Show the plot\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:30:30.345765Z",
     "start_time": "2024-10-16T18:30:30.236941Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group label counts:\n",
      "0    21\n",
      "3    10\n",
      "1     4\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Prepare Group Labels\n",
    "\n",
    "# Load phenotypic data\n",
    "phenotypic = pd.read_csv(phenotypic_file, sep='\\t')\n",
    "\n",
    "# make subject ids into ints\n",
    "int_subject_ids = [int(x) for x in subject_ids]\n",
    "\n",
    "# Ensure the subject IDs match\n",
    "phenotypic = phenotypic.set_index('ScanDir ID').loc[int_subject_ids].reset_index()\n",
    "\n",
    "group_labels = phenotypic['DX'].values\n",
    "\n",
    "# Check the distribution of group labels\n",
    "print('Group label counts:')\n",
    "print(pd.Series(group_labels).value_counts())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diagnosis\n",
    "- 0 Typically Developing Children\n",
    "- 1 ADHD-Combined\n",
    "- 2 ADHD-Hyperactive/Impulsive\n",
    "- 3 ADHD-Inattentive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideas\n",
    "\n",
    "- combine all adhd classes into 1 and non-adhd to 0. Having more than 1 class of the adhd diagnosis is more difficult to diagnose from the cnn rather than just having 1 total ADHD class\n",
    "\n",
    "- we could trim ROIS down in future versions. [Paper discussing this](https://pubmed.ncbi.nlm.nih.gov/38476041/)\n",
    "![Alt text](/Users/user/Documents/GitHub/adhd-mri-using-ml/Subcortical-and-cortical-Regions-of-Interest-ROIs-Subcortical-ROIs-1a-Amy-amygdala.jpg \"a title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:59:42.246928Z",
     "start_time": "2024-10-16T18:58:58.216397Z"
    }
   },
   "outputs": [],
   "source": [
    "X = np.array(all_correlation_matrices)# Use cross-validation for evaluation\n",
    "kf = KFold(n_splits=5)\n",
    "scores = []\n",
    "\n",
    "for train_idx, test_idx in kf.split(conditions):\n",
    "    decoder.fit(image.index_img(fmri_imgs, train_idx), conditions[train_idx])\n",
    "    preds = decoder.predict(image.index_img(fmri_imgs, test_idx))\n",
    "    accuracy = (preds == conditions[test_idx]).mean()\n",
    "    scores.append(accuracy)\n",
    "\n",
    "print(f\"Cross-validation Accuracy: {np.mean(scores):.2f}\")\n",
    "\n",
    "\n",
    "for label in group_labels:\n",
    "    if (label == '3'):\n",
    "        label = '1'\n",
    "y = group_labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T18:59:50.681469Z",
     "start_time": "2024-10-16T18:59:50.676624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (35, 2843, 2843)\n",
      "Labels shape: (35,)\n",
      "New Data shape: (35, 2843, 2843)\n",
      "New Labels shape: (35,)\n"
     ]
    }
   ],
   "source": [
    "print(f'Data shape: {X.shape}')\n",
    "print(f'Labels shape: {y.shape}')\n",
    "\n",
    "X_train = X_train[..., np.newaxis]  # Shape: (n_samples, n_rois, n_rois, 1)\n",
    "X_test = X_test[..., np.newaxis]\n",
    "\n",
    "print(f'New Data shape: {X.shape}')\n",
    "print(f'New Labels shape: {y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-16T19:00:30.116097Z",
     "start_time": "2024-10-16T18:59:52.381182Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train data type: float32\n",
      "y_train data type: object\n",
      "new X_train data type: float64\n",
      "new y_train data type: float64\n"
     ]
    }
   ],
   "source": [
    "print(f'X_train data type: {X_train.dtype}')\n",
    "print(f'y_train data type: {y_train.dtype}')\n",
    "\n",
    "X_train = X_train.astype(float)\n",
    "y_train = y_train.astype(float)\n",
    "\n",
    "print(f'new X_train data type: {X_train.dtype}')\n",
    "print(f'new y_train data type: {y_train.dtype}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-20 00:13:45.644223: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:359] gpu_async_1 cuMemAllocAsync failed to allocate 8235925504 bytes: RESOURCE_EXHAUSTED: : CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      " Reported by CUDA: Free memory/Total memory: 1615462400/21125267456\n",
      "2024-11-20 00:13:45.644244: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:364] Stats: Limit:                     19334299648\n",
      "InUse:                     16471927384\n",
      "MaxInUse:                  16471927388\n",
      "NumAllocs:                          38\n",
      "MaxAllocSize:               8235925504\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2024-11-20 00:13:45.644249: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:68] Histogram of current allocation: (allocation_size_in_bytes, nb_allocation_of_that_sizes), ...;\n",
      "2024-11-20 00:13:45.644252: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 4, 7\n",
      "2024-11-20 00:13:45.644254: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 8, 3\n",
      "2024-11-20 00:13:45.644257: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 16, 2\n",
      "2024-11-20 00:13:45.644259: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 128, 1\n",
      "2024-11-20 00:13:45.644261: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 256, 1\n",
      "2024-11-20 00:13:45.644263: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 1028, 1\n",
      "2024-11-20 00:13:45.644265: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 1152, 1\n",
      "2024-11-20 00:13:45.644267: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 73728, 1\n",
      "2024-11-20 00:13:45.644269: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:71] 8235925504, 2\n",
      "2024-11-20 00:13:45.644272: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:104] CU_MEMPOOL_ATTR_RESERVED_MEM_CURRENT: 19327352832\n",
      "2024-11-20 00:13:45.644275: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:106] CU_MEMPOOL_ATTR_USED_MEM_CURRENT: 16471927384\n",
      "2024-11-20 00:13:45.644277: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:107] CU_MEMPOOL_ATTR_RESERVED_MEM_HIGH: 20937965568\n",
      "2024-11-20 00:13:45.644279: E external/local_xla/xla/stream_executor/gpu/gpu_cudamallocasync_allocator.cc:108] CU_MEMPOOL_ATTR_USED_MEM_HIGH: 16471927388\n",
      "2024-11-20 00:13:45.644284: W tensorflow/core/framework/op_kernel.cc:1829] RESOURCE_EXHAUSTED: failed to allocate memory\n",
      "2024-11-20 00:13:45.644290: I tensorflow/core/framework/local_rendezvous.cc:405] Local rendezvous is aborting with status: RESOURCE_EXHAUSTED: failed to allocate memory\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "{{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2] name: ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 10\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Resize images\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# X_train_resized = tf.image.resize(X_train, (512, 512))\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# X_test_resized = tf.image.resize(X_test, (512, 512))\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# y_train_resized = tf.image.resize(y_train, (512, 512))\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# y_test_resized = tf.image.resize(y_test, (512, 512))\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m strategy\u001b[38;5;241m.\u001b[39mscope():\n\u001b[0;32m---> 10\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mmodels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSequential\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#layers.Input(shape=(512, 512, 1)),\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInput\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2843\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m2843\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMaxPooling2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mConv2D\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkernel_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMaxPooling2D\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFlatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrelu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDropout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayers\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDense\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlinear\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m     opt \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m     23\u001b[0m     model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mopt, loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/adhd/lib/python3.12/site-packages/keras/src/models/sequential.py:76\u001b[0m, in \u001b[0;36mSequential.__init__\u001b[0;34m(self, layers, trainable, name)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m layers:\n\u001b[1;32m     75\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd(layer, rebuild\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_rebuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/adhd/lib/python3.12/site-packages/keras/src/models/sequential.py:141\u001b[0m, in \u001b[0;36mSequential._maybe_rebuild\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m], InputLayer) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    140\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mbatch_shape\n\u001b[0;32m--> 141\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuild\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;66;03m# We can build the Sequential model if the first layer has the\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# `input_shape` property. This is most commonly found in Functional\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;66;03m# model.\u001b[39;00m\n\u001b[1;32m    146\u001b[0m     input_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39minput_shape\n",
      "File \u001b[0;32m~/anaconda3/envs/adhd/lib/python3.12/site-packages/keras/src/layers/layer.py:226\u001b[0m, in \u001b[0;36mLayer.__new__.<locals>.build_wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_open_name_scope():\n\u001b[1;32m    225\u001b[0m     obj\u001b[38;5;241m.\u001b[39m_path \u001b[38;5;241m=\u001b[39m current_path()\n\u001b[0;32m--> 226\u001b[0m     \u001b[43moriginal_build_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;66;03m# Record build config.\u001b[39;00m\n\u001b[1;32m    228\u001b[0m signature \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(original_build_method)\n",
      "File \u001b[0;32m~/anaconda3/envs/adhd/lib/python3.12/site-packages/keras/src/models/sequential.py:187\u001b[0m, in \u001b[0;36mSequential.build\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layers[\u001b[38;5;241m1\u001b[39m:]:\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 187\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    188\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m:\n\u001b[1;32m    189\u001b[0m         \u001b[38;5;66;03m# Can happen if shape inference is not implemented.\u001b[39;00m\n\u001b[1;32m    190\u001b[0m         \u001b[38;5;66;03m# TODO: consider reverting inbound nodes on layers processed.\u001b[39;00m\n\u001b[1;32m    191\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/adhd/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/adhd/lib/python3.12/site-packages/keras/src/backend/tensorflow/random.py:34\u001b[0m, in \u001b[0;36muniform\u001b[0;34m(shape, minval, maxval, dtype, seed)\u001b[0m\n\u001b[1;32m     32\u001b[0m dtype \u001b[38;5;241m=\u001b[39m dtype \u001b[38;5;129;01mor\u001b[39;00m floatx()\n\u001b[1;32m     33\u001b[0m seed \u001b[38;5;241m=\u001b[39m _cast_seed(draw_seed(seed))\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstateless_uniform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshape\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43mminval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mminval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaxval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaxval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: {{function_node __wrapped__AddV2_device_/job:localhost/replica:0/task:0/device:GPU:0}} failed to allocate memory [Op:AddV2] name: "
     ]
    }
   ],
   "source": [
    "from keras import layers, models\n",
    "\n",
    "with strategy.scope():\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(2843,2843,1)),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(1, activation='linear')\n",
    "    ])\n",
    "    opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    model.compile(optimizer=opt, loss='mean_squared_error', metrics=['accuracy'])\n",
    "\n",
    "# Adjust batch size dynamically\n",
    "batch_size = 4\n",
    "while True:\n",
    "    try:\n",
    "        history = model.fit(X_train, y_train, epochs=5, batch_size=batch_size, validation_split=0.2)\n",
    "        break\n",
    "    except tf.errors.ResourceExhaustedError:\n",
    "        batch_size //= 2\n",
    "        if batch_size == 0:\n",
    "            raise ValueError(\"Not enough GPU memory to process the data with current settings.\")\n",
    "        print(f\"Reducing batch size to {batch_size}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X_test.astype(float)\n",
    "y_test = y_test.astype(float)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f'Test accuracy: {test_acc}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "adhd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
