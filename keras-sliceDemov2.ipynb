{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal: Generate slices of fmri scans, then use a classfier to train on newly created slices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "from pathlib import Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SLICE GENERATOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU details:  {'device_name': 'METAL'}\n"
     ]
    }
   ],
   "source": [
    "devices = tf.config.list_physical_devices()\n",
    "# print(\"\\nDevices: \", devices)\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  details = tf.config.experimental.get_device_details(gpus[0])\n",
    "  print(\"GPU details: \", details)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_path = os.path.join('data','fmri','beijing')\n",
    "savepath = os.path.join('outputs','slice-outputs')\n",
    "fmri_files = Path(\"data/fmri/beijing\").glob(\"*.nii.gz\")\n",
    "count = 0\n",
    "\n",
    "def slice_gen(imagename,x):\n",
    "    \n",
    "    slice_data = test_img_data[:,:,20,x]\n",
    "\n",
    "    plt.imshow(slice_data, cmap='gray')\n",
    "    plt.axis('off')  # Turn off axis labels\n",
    "    plt.savefig(savepath + \"/\"+ imagename, bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()\n",
    "\n",
    "for files in fmri_files:\n",
    "    imgname = 'output' + str(count) + '.png'\n",
    "    test_img = nib.load(str(files))\n",
    "    test_img_data = test_img.get_fdata()\n",
    "    #for x in range (0, 3):\n",
    "    slice_gen(imgname,count)\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CLASSIFIER\n",
    "code from: https://www.kaggle.com/code/stefanie04736/simple-keras-model-with-k-fold-cross-validation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Convolution2D, MaxPooling2D, GlobalAveragePooling2D, BatchNormalization\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "%matplotlib inline\n",
    "keras.backend.set_image_data_format('channels_last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_kfold(k):\n",
    "    \n",
    "    train = pd.read_json('../input/train.json')\n",
    "    train.inc_angle = train.inc_angle.replace('na', 0)\n",
    "    \n",
    "    x_band1 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_1\"]])\n",
    "    x_band2 = np.array([np.array(band).astype(np.float32).reshape(75, 75) for band in train[\"band_2\"]])\n",
    "    x_band3 = x_band1 / x_band2\n",
    "       \n",
    "    X_train = np.concatenate([x_band1[:, :, :, np.newaxis]\n",
    "                            , x_band2[:, :, :, np.newaxis]\n",
    "                            , x_band3[:, :, :, np.newaxis]], axis=-1)\n",
    "                         \n",
    "    y_train = np.array(train[\"is_iceberg\"])\n",
    "    \n",
    "    folds = list(StratifiedKFold(n_splits=k, shuffle=True, random_state=1).split(X_train, y_train))\n",
    "    \n",
    "    return folds, X_train, y_train\n",
    "\n",
    "k = 7\n",
    "folds, X_train, y_train = load_data_kfold(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \n",
    "    x = Input((75, 75, 3))\n",
    "    model = BatchNormalization(axis = 3)(x)\n",
    "    model = Convolution2D(filters = 32, kernel_size = (3,3), strides = (1,1), padding = 'same', activation='relu')(model)\n",
    "    model = MaxPooling2D()(model)\n",
    "    \n",
    "    model = BatchNormalization(axis = 3)(model)\n",
    "    model = Convolution2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', activation='relu')(model)\n",
    "    model = MaxPooling2D()(model)\n",
    "    \n",
    "    model = BatchNormalization(axis = 3)(model)\n",
    "    model = Convolution2D(filters = 128, kernel_size = (3,3), strides = (1,1), padding = 'same', activation='relu')(model)\n",
    "    model = MaxPooling2D()(model)\n",
    "    \n",
    "    model = BatchNormalization(axis = 3)(model)\n",
    "    model = Convolution2D(filters = 64, kernel_size = (3,3), strides = (1,1), padding = 'same', activation='relu')(model) \n",
    "    model = GlobalAveragePooling2D()(model)\n",
    " \n",
    "    model = Dense(1, activation = 'sigmoid')(model)\n",
    "    \n",
    "    model = Model(input = x, output = model)\n",
    "    \n",
    "    opt_adam = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "    model.compile(opt_adam, loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=64\n",
    "\n",
    "gen = ImageDataGenerator(horizontal_flip = True,\n",
    "                         vertical_flip = True,\n",
    "                         width_shift_range = 0.1,\n",
    "                         height_shift_range = 0.1,\n",
    "                         zoom_range = 0.1,\n",
    "                         rotation_range = 10\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_callbacks(name_weights, patience_lr):\n",
    "    mcp_save = ModelCheckpoint(name_weights, save_best_only=True, monitor='val_loss', mode='min')\n",
    "    reduce_lr_loss = ReduceLROnPlateau(monitor='loss', factor=0.1, patience=patience_lr, verbose=1, epsilon=1e-4, mode='min')\n",
    "    return [mcp_save, reduce_lr_loss]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j, (train_idx, val_idx) in enumerate(folds):\n",
    "    \n",
    "    print('\\nFold ',j)\n",
    "    X_train_cv = X_train[train_idx]\n",
    "    y_train_cv = y_train[train_idx]\n",
    "    X_valid_cv = X_train[val_idx]\n",
    "    y_valid_cv= y_train[val_idx]\n",
    "    \n",
    "    name_weights = \"final_model_fold\" + str(j) + \"_weights.h5\"\n",
    "    callbacks = get_callbacks(name_weights = name_weights, patience_lr=10)\n",
    "    generator = gen.flow(X_train_cv, y_train_cv, batch_size = batch_size)\n",
    "    model = get_model()\n",
    "    model.fit_generator(\n",
    "                generator,\n",
    "                steps_per_epoch=len(X_train_cv)/batch_size,\n",
    "                epochs=15,\n",
    "                shuffle=True,\n",
    "                verbose=1,\n",
    "                validation_data = (X_valid_cv, y_valid_cv),\n",
    "                callbacks = callbacks)\n",
    "    \n",
    "    print(model.evaluate(X_valid_cv, y_valid_cv))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "keras-ADHD",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
